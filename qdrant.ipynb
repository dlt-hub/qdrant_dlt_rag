{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QueryResponse(id='4cb66f4a-8f20-5363-9fc7-322ad5fdc15d', embedding=None, metadata={'_dlt_id': 'XAS0KiLsPAOnFQ', '_dlt_load_id': '1701704878.659247', 'backstory': 'A scientist by day, a virtual adventurer by night', 'city': 'South Tracy', 'email': 'smckay@yahoo.com', 'favorite_gaming_moment': 'Recalls the epic win in the final seconds of a battle royale game', 'hobbies': 'Loves hiking and photography', 'in_game_behavior': 'Diplomatic and a team player, excels in cooperative tasks', 'name': 'Brent Robinson', 'personality_description': 'Competitive spirit, always aiming for the top scores', 'rfam_acc': 'RF00004'}, document='', score=0.80612046),\n",
       " QueryResponse(id='bde05b88-a367-5786-b779-40c85788433f', embedding=None, metadata={'_dlt_id': 'o2K6zysnQrqW3Q', '_dlt_load_id': '1701704878.659247', 'backstory': 'A retired superhero, finds solace in virtual battles', 'city': 'Lake Richard', 'email': 'vanessa12@russell-reynolds.com', 'favorite_gaming_moment': 'Fondly remembers building an entire empire in a strategy game', 'hobbies': 'Loves hiking and photography', 'in_game_behavior': 'Diplomatic and a team player, excels in cooperative tasks', 'name': 'Keith Nelson', 'personality_description': 'Calm and patient, prefers long strategy games', 'rfam_acc': 'RF00005'}, document='', score=0.8012494),\n",
       " QueryResponse(id='0d7b2e69-2f42-5915-9faf-b6f029c97211', embedding=None, metadata={'_dlt_id': 'qMs8i2B2cdBvdw', '_dlt_load_id': '1701704878.659247', 'backstory': 'A retired superhero, finds solace in virtual battles', 'city': 'North Tracey', 'email': 'annwhite@hotmail.com', 'favorite_gaming_moment': 'Proud of solving an almost impossible puzzle after many tries', 'hobbies': 'Avid reader and writer', 'in_game_behavior': 'Often the team strategist, prefers support roles', 'name': '', 'personality_description': 'Calm and patient, prefers long strategy games', 'rfam_acc': 'RF00006'}, document='', score=0.7967884),\n",
       " QueryResponse(id='8bfd5d4e-b900-57d1-90f4-f41a35dff05a', embedding=None, metadata={'_dlt_id': 'rkTeLuNZz5PMTw', '_dlt_load_id': '1701704883.967057', 'communication_preference': 'Prefers email communication for detailed discussions', 'company': 'Lyons, Long and Leach', 'email': 'patelallison@richardson.biz', 'email_analysis': 'Creative email address, shows a personal touch', 'phone_number': '+1-073-733-1139', 'professional_summary': 'Marketing and sales expert', 'rfam_acc': 'RF00003'}, document='', score=0.7877501),\n",
       " QueryResponse(id='b58c3fe5-1c4b-5c9f-832d-cb0692c220ad', embedding=None, metadata={'_dlt_id': 'ypCedCIVj9ZG/Q', '_dlt_load_id': '1701704883.967057', 'communication_preference': 'Favors quick phone calls for immediate resolution', 'company': 'Li-Taylor', 'email': 'derrickoneill@gmail.com', 'email_analysis': 'Simple and memorable email, easy to recall', 'phone_number': '(503)108-5391', 'professional_summary': 'Human resources specialist, focusing on talent development', 'rfam_acc': 'RF00002'}, document='', score=0.76520646),\n",
       " QueryResponse(id='9c158837-99f5-5d39-bae4-5768e9fee328', embedding=None, metadata={'_dlt_id': 'ZE0NLELQVklvvg', '_dlt_load_id': '1701704883.967057', 'communication_preference': 'Favors quick phone calls for immediate resolution', 'company': 'Wilkinson-Glover', 'email': 'kathrynmorris@yahoo.com', 'email_analysis': 'Simple and memorable email, easy to recall', 'phone_number': '001-771-400-7699x97766', 'professional_summary': 'Operations guru, ensuring smooth processes', 'rfam_acc': 'RF00001'}, document='', score=0.7642092)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Qdrant\n",
    "qdrant_client = QdrantClient(\n",
    "    \"https://3ad0d7d5-4015-4ccc-b8d5-c09f8121bd2b.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"GP2xb22FrO1cMMBBcaxkGJHzWHBBf86yms7u48Sxjco1LoENfXlo8Q\",\n",
    ")\n",
    "\n",
    "qdrant_client.query(\n",
    "    collection_name=\"mydata_content\",\n",
    "    query_text=\"Who likes taking pictures?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_chatgpt_output(query: str, context: str = None, api_key=None, model_name=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Generate a response from the OpenAI ChatGPT model.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query or message.\n",
    "        context (str, optional): Additional context for the conversation. Defaults to an empty string.\n",
    "        api_key (str, optional): Your OpenAI API key. If not provided, the globally configured API key will be used.\n",
    "        model_name (str, optional): The name of the ChatGPT model to use. Defaults to \"gpt-3.5-turbo\".\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated by the ChatGPT model.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If an error occurs during the API call, an error message is returned for the caller to handle.\n",
    "    \"\"\"\n",
    "    if not context:\n",
    "        context = \"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"assistant\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        openai.api_key = api_key if api_key else openai.api_key  # Use the provided API key or the one set globally\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        llm_output = response.choices[0].message.content\n",
    "        return llm_output\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"  # Return the error message for the caller to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "async def eval_test(\n",
    "    query=None,\n",
    "    output=None,\n",
    "    expected_output=None,\n",
    "    context=None,\n",
    "    synthetic_test_set=False,\n",
    "):\n",
    "    logging.info(\"Generating chatgpt output\")\n",
    "    result_output = await generate_chatgpt_output(query, str(context))\n",
    "\n",
    "    logging.info(\"Moving on\")\n",
    "\n",
    "    if synthetic_test_set:\n",
    "        test_case = synthetic_test_set\n",
    "    else:\n",
    "        test_case = LLMTestCase(\n",
    "            input=str(query),\n",
    "            actual_output=str(result_output),\n",
    "            expected_output=str(expected_output),\n",
    "            context=[str(context)],\n",
    "        )\n",
    "    metric = OverallScoreMetric()\n",
    "\n",
    "    # If you want to run the test\n",
    "    test_result = run_test(test_case, metrics=[metric], raise_error=False)\n",
    "\n",
    "    def test_result_to_dict(test_result):\n",
    "        return {\n",
    "            \"success\": test_result.success,\n",
    "            \"score\": test_result.score,\n",
    "            \"metric_name\": test_result.metric_name,\n",
    "            \"query\": test_result.query,\n",
    "            \"output\": test_result.output,\n",
    "            \"expected_output\": test_result.expected_output,\n",
    "            \"metadata\": test_result.metadata,\n",
    "            \"context\": test_result.context,\n",
    "        }\n",
    "\n",
    "    test_result_dict = []\n",
    "    for test in test_result:\n",
    "        test_result_it = test_result_to_dict(test)\n",
    "        test_result_dict.append(test_result_it)\n",
    "    return test_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_eval(test_item, search_result):\n",
    "    logging.info(\"Initiated test set evaluation\")\n",
    "    test_eval = await eval_test(\n",
    "        query=str(test_item[\"question\"]),\n",
    "        expected_output=str(test_item[\"answer\"]),\n",
    "        context=str(search_result),\n",
    "    )\n",
    "    logging.info(\"Successfully evaluated test set\")\n",
    "    return test_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
